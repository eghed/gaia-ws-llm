{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from typing import Dict, Optional, List\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, AutoPeftModelForCausalLM\n",
    "from transformers import TrainingArguments, BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "from trl import DPOTrainer, SFTTrainer\n",
    "\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preparing a dataset \n",
    "We are using a Huggingface hosted dataset consisting of Stackoverflow questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset ARGS:\n",
    "\n",
    "ds_name = \"MaestroDmitry/stack-exchange-paired-shorted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huggingface DPO trainer needs a dataset containing prompts, chosen, and rejected\n",
    "\n",
    "def return_prompts_and_responses(batch: Dict[str, List[str]]) -> Dict[str, List[str]]:\n",
    "    prompts = [f\"Question: {question} \\n\\nAnswer: \" for question in batch[\"question\"]]\n",
    "    return {\n",
    "        'prompt': list(prompts),\n",
    "        'chosen': list(batch[\"response_j\"]),\n",
    "        'rejected': list(batch[\"response_k\"])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset from Huggingface\n",
    "dataset = load_dataset(\n",
    "    ds_name,\n",
    "    cache_dir=\"llm-finetune/data\"\n",
    ")\n",
    "\n",
    "dataset = dataset.map(\n",
    "    function=return_prompts_and_responses,\n",
    "    batched=True,\n",
    "    with_indices=False,\n",
    "    remove_columns=dataset['train'].column_names\n",
    ")\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a SFT base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"EleutherAI/gpt-neo-1.3B\"\n",
    "# model_path = \"ComCom/gpt2-small\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# load the base model in 4-bit quantization\n",
    "# TODO this only works on cuda\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto',  # {\"\": 0},\n",
    "    trust_remote_code=True,\n",
    "    # use_auth_token=True,\n",
    "    cache_dir=\"llm-finetune/model/base\"\n",
    ")\n",
    "\n",
    "base_model.config.use_cache = False\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    base_model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "print(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sft_formatting_func(example):\n",
    "    output_texts = []\n",
    "    output_texts.append(f\"### Question: {example['prompt']}\\n ### Answer: {example['chosen']}\")\n",
    "    output_texts.append(f\"### Question: {example['prompt']}\\n ### Answer: {example['rejected']}\")\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Lora args:\n",
    "lora_r = 8\n",
    "lora_alpha = 8\n",
    "lora_dropout = 0.0\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    target_modules=[\"c_proj\"],  # [\"q_proj\", \"v_proj\"],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_training_args: TrainingArguments = TrainingArguments(\n",
    "    output_dir=\"llm-finetune/model/sft_train\",\n",
    "    # use_cpu=True,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_gpu_eval_batch_size=2,\n",
    "    logging_dir='llm-finetune/logs/sft_train'\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=base_model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    peft_config=peft_config,\n",
    "    packing=True,  # Used only in case `dataset_text_field` is passed. This argument is used by the `ConstantLengthDataset` to pack the sequences of the dataset.\n",
    "    max_seq_length=None,  # The maximum sequence length to use for the `ConstantLengthDataset` and for automatically creating the Dataset. Defaults to `512`.\n",
    "    formatting_func=sft_formatting_func,\n",
    "    tokenizer=tokenizer,\n",
    "    args=sft_training_args,  # HF Trainer arguments\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "\n",
    "# On single A10-G = 15h\n",
    "# On dual rtx 3090 = 8h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO load pre trained model here instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DPO Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_beta: float = 0.1\n",
    "dpo_training_args: Optional[TrainingArguments] = TrainingArguments(\n",
    "    output_dir=\"llm-finetune/model/dpo_train\",\n",
    "    # use_cpu=True,\n",
    "    per_device_train_batch_size=1,  # TODO DPO seems to use one model / gpu, so i can up this!\n",
    "    per_gpu_eval_batch_size=1,\n",
    ")\n",
    "\n",
    "dpo_model = \"llm-finetune/sft_train/checkpoint-1000\"\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    dpo_model,  # location of saved SFT model\n",
    "    device_map='auto',  # {\"\": 0},\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=bnb_config,\n",
    "    is_trainable=True,\n",
    ")\n",
    "\n",
    "dpo_model_ref = \"llm-finetune/sft_train/checkpoint-1000\"\n",
    "model_ref = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    dpo_model_ref,  # same model as the main one\n",
    "    device_map='auto',  # {\"\": 0},\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "\n",
    "dpo_trainer = DPOTrainer(\n",
    "    model,\n",
    "    model_ref,\n",
    "    args=dpo_training_args,\n",
    "    beta=dpo_beta,\n",
    "    train_dataset=dpo_train_dataset,\n",
    "    eval_dataset=dpo_test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_trainer.train()\n",
    "dpo_trainer.save_model()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
